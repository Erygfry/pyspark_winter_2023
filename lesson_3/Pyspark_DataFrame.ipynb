{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WHgYpJXKoPIi",
    "outputId": "4c0d4c16-0e2d-4b51-ba08-c5dfae3d2933"
   },
   "outputs": [],
   "source": [
    "!pip install pyspark findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mUBraSjDoaDp"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyspark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msql\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m      5\u001b[39m conf = SparkConf().set(\u001b[33m'\u001b[39m\u001b[33mspark.ui.port\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m4050\u001b[39m\u001b[33m'\u001b[39m).set(\u001b[33m'\u001b[39m\u001b[33mspark.serializer\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33morg.apache.spark.serializer.KryoSerializer\u001b[39m\u001b[33m'\u001b[39m)\\\n\u001b[32m      6\u001b[39m                   .set(\u001b[33m'\u001b[39m\u001b[33mspark.dynamicAllocation.enabled\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m'\u001b[39m)\\\n\u001b[32m      7\u001b[39m                   .set(\u001b[33m'\u001b[39m\u001b[33mspark.shuffle.service.enabled\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;66;03m#трекер, чтобы возвращать ресурсы\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m sc = \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m spark = SparkSession.builder.master(\u001b[33m'\u001b[39m\u001b[33mlocal[*]\u001b[39m\u001b[33m'\u001b[39m).getOrCreate()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Petr\\PycharmProjects\\pyspark_winter_2023\\venv\\Lib\\site-packages\\pyspark\\core\\context.py:205\u001b[39m, in \u001b[36mSparkContext.__init__\u001b[39m\u001b[34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway.gateway_parameters.auth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m is not allowed as it is a security risk.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28mself\u001b[39m._do_init(\n\u001b[32m    208\u001b[39m         master,\n\u001b[32m    209\u001b[39m         appName,\n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m         memory_profiler_cls,\n\u001b[32m    220\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Petr\\PycharmProjects\\pyspark_winter_2023\\venv\\Lib\\site-packages\\pyspark\\core\\context.py:444\u001b[39m, in \u001b[36mSparkContext._ensure_initialized\u001b[39m\u001b[34m(cls, instance, gateway, conf)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext._lock:\n\u001b[32m    443\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext._gateway:\n\u001b[32m--> \u001b[39m\u001b[32m444\u001b[39m         SparkContext._gateway = gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    445\u001b[39m         SparkContext._jvm = SparkContext._gateway.jvm\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Petr\\PycharmProjects\\pyspark_winter_2023\\venv\\Lib\\site-packages\\pyspark\\java_gateway.py:108\u001b[39m, in \u001b[36mlaunch_gateway\u001b[39m\u001b[34m(conf, popen_kwargs)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m proc.poll() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isfile(conn_info_file):\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isfile(conn_info_file):\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkRuntimeError(\n\u001b[32m    112\u001b[39m         errorClass=\u001b[33m\"\u001b[39m\u001b[33mJAVA_GATEWAY_EXITED\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    113\u001b[39m         messageParameters={},\n\u001b[32m    114\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "conf = (\n",
    "    SparkConf()\n",
    "    .set(\"spark.ui.port\", \"4050\")\n",
    "    .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "    .set(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "    .set(\"spark.shuffle.service.enabled\", \"true\")\n",
    ")  # трекер, чтобы возвращать ресурсы\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aidzIxBod4z5",
    "outputId": "ff6d75b2-606c-4611-b3d2-c5450ec96915"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdchPhE6osBh"
   },
   "source": [
    "**Создание DataFrame**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DuQZiqE8pLBg"
   },
   "source": [
    "Из RDD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0HRKDcbpeT1"
   },
   "outputs": [],
   "source": [
    "def cleaning(row):\n",
    "    row = row.split(\"\\t\")[:3]\n",
    "    row = [float(val) for val in row]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83oW4J6ioqwt"
   },
   "outputs": [],
   "source": [
    "ratings = sc.textFile(\"user_ratedmovies.dat\")\n",
    "\n",
    "first_row = ratings.first()\n",
    "ratings = ratings.filter(lambda row: row != first_row).map(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fs-On6Warlgm"
   },
   "outputs": [],
   "source": [
    "columns = first_row.split(\"\\t\")[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3JWv9Cdr1y7",
    "outputId": "5463f2a9-b945-4ce7-a0a7-5650c0081b11"
   },
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0HHFa4NOpl8U",
    "outputId": "9ecb83f7-486c-44db-b819-fcfb11ee61ba"
   },
   "outputs": [],
   "source": [
    "ratings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6EbyjOzp2Rz"
   },
   "outputs": [],
   "source": [
    "df_rdd = spark.createDataFrame(ratings, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "grAj61Pqqcot",
    "outputId": "73506e0d-7db6-4e11-8840-98281f9a0244"
   },
   "outputs": [],
   "source": [
    "df_rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGdP3oErrBn2"
   },
   "source": [
    "Можно еще вот так:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pm2IjgCKrGQR"
   },
   "outputs": [],
   "source": [
    "df_rdd = ratings.toDF(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bNeXMPNQsLV1",
    "outputId": "6a9da5fc-aee0-46f6-8f60-120e56f1a68c"
   },
   "outputs": [],
   "source": [
    "df_rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cHlkz0Rsf2W"
   },
   "source": [
    "Так, а если не хочу вот эти приседания с RDD, а хочу сразу из файла?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFkXM_vZu_1t"
   },
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .options(**{\"sep\": \"\\t\", \"header\": \"true\"})\n",
    "    .load(\"user_ratedmovies.dat\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AlZNFbmpvQKN",
    "outputId": "e3ce4050-7fa5-4c93-e7d5-88435140aa91"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2tEvxnrxka6"
   },
   "source": [
    "Все в string, так не пойдет, давайте автоматически определим тип данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QTXHlh2msvaY"
   },
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .options(**{\"sep\": \"\\t\", \"header\": \"true\", \"inferSchema\": \"true\"})\n",
    "    .load(\"user_ratedmovies.dat\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84-8zIkJzgGC",
    "outputId": "c846221d-2dec-4a1d-8871-2acad9d41b4e"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJcH3xqwz5JC",
    "outputId": "097ddd79-d895-4900-9b8f-b0cc15e43fcc"
   },
   "outputs": [],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65EYIo0O1v2s"
   },
   "source": [
    "А можно заранее сказать, какой тип данных я ожидаю?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LBTjPC1-102G"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    IntegerType,\n",
    "    DoubleType,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axRDyclD3YZX"
   },
   "outputs": [],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"userID\", IntegerType(), True),\n",
    "        StructField(\"movieID\", IntegerType(), True),\n",
    "        StructField(\"rating\", DoubleType(), True),\n",
    "        StructField(\"date_day\", StringType(), True),\n",
    "        StructField(\"date_month\", StringType(), True),\n",
    "        StructField(\"date_year\", IntegerType(), True),\n",
    "        StructField(\"date_hour\", IntegerType(), True),\n",
    "        StructField(\"date_minute\", IntegerType(), True),\n",
    "        StructField(\"date_second\", IntegerType(), True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y16zNsdF4GdA"
   },
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .options(**{\"sep\": \"\\t\", \"header\": \"true\"})\n",
    "    .schema(schema)\n",
    "    .load(\"user_ratedmovies.dat\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zyZqtXpN4Teq",
    "outputId": "ac0af62a-62d6-47b9-ff37-abe101f76f0c"
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E7hegloJ4W0j",
    "outputId": "9584de88-852d-4d56-c775-5db1d73d6b3d"
   },
   "outputs": [],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mdxJ2Mts42yh"
   },
   "source": [
    "Но есть уже готовая обертка под все нужды\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Z3BQYgq46H2"
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\n",
    "    path=\"user_ratedmovies.dat\", sep=\"\\t\", header=True, inferSchema=True, schema=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L_QGJgItBcr5",
    "outputId": "15336e54-32eb-4570-f6e3-cbdd5bc462b3"
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-AikPkbuN44v"
   },
   "source": [
    "Так, а как сохранить? Лучше быть аккуратнее с overwrite, перезапишет весь указанный путь, append будет безопаснее\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvoejV_lN7Wx"
   },
   "outputs": [],
   "source": [
    "df.write.option(\"header\", True).mode(\"overwrite\").parquet(\"write_1.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9FAZTtsOU_D"
   },
   "source": [
    "А что с партицированием?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5DXXgA5OUJL"
   },
   "outputs": [],
   "source": [
    "df.write.option(\"header\", True).partitionBy(\"date_year\").mode(\"overwrite\").parquet(\n",
    "    \"write_2.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVWgHcej7BW8"
   },
   "source": [
    "Кстати, раз уж заговорили про схемы данных, то их можно задавать интереснее, например, под группированные данные\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CGlOCL_f7K6S",
    "outputId": "88b3fb4f-8e08-4c53-d192-74f708e073c6"
   },
   "outputs": [],
   "source": [
    "structureData = [\n",
    "    ((\"James\", \"\", \"Smith\"), \"36636\", \"M\", 3100),\n",
    "    ((\"Michael\", \"Rose\", \"\"), \"40288\", \"M\", 4300),\n",
    "    ((\"Robert\", \"\", \"Williams\"), \"42114\", \"M\", 1400),\n",
    "    ((\"Maria\", \"Anne\", \"Jones\"), \"39192\", \"F\", 5500),\n",
    "    ((\"Jen\", \"Mary\", \"Brown\"), \"\", \"F\", -1),\n",
    "]\n",
    "structureSchema = StructType(\n",
    "    [\n",
    "        StructField(\n",
    "            \"name\",\n",
    "            StructType(\n",
    "                [\n",
    "                    StructField(\"firstname\", StringType(), True),\n",
    "                    StructField(\"middlename\", StringType(), True),\n",
    "                    StructField(\"lastname\", StringType(), True),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"gender\", StringType(), True),\n",
    "        StructField(\"salary\", IntegerType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "df2 = spark.createDataFrame(data=structureData, schema=structureSchema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iClIlEKr8iTj"
   },
   "source": [
    "Со структурой можно работать и менять ее под ваши нужны\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vm4_WIJS8dgO",
    "outputId": "63e0d872-ab47-4e6d-9664-648181bdef58"
   },
   "outputs": [],
   "source": [
    "updatedDF = df2.withColumn(\n",
    "    \"OtherInfo\",\n",
    "    F.struct(\n",
    "        F.col(\"id\").alias(\"identifier\"),\n",
    "        F.col(\"gender\").alias(\"gender\"),\n",
    "        F.col(\"salary\").alias(\"salary\"),\n",
    "\n",
    "        F.when(F.col(\"salary\").cast(IntegerType()) < 2000, \"Low\")\n",
    "        .when(F.col(\"salary\").cast(IntegerType()) < 4000, \"Medium\")\n",
    "        .otherwise(\"High\")\n",
    "        .alias(\"Salary_Grade\"),\n",
    "    ),\n",
    ").drop(\"id\", \"gender\", \"salary\")\n",
    "\n",
    "\n",
    "\n",
    "updatedDF.printSchema()\n",
    "\n",
    "\n",
    "updatedDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0ahr4fX9Upl"
   },
   "source": [
    "Что мы там сделали????\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LDl88xh9ijH"
   },
   "source": [
    "1. Создали новую структуру данных OtherInfo\n",
    "\n",
    "2. Передали туда id (переименовав столбец), gender, salary\n",
    "\n",
    "3. Создали столбец Salary_grade из условий\n",
    "\n",
    "4. удалили id, gender, salary из старой структуры\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCQAE9lcB9t0"
   },
   "source": [
    "Есть и еще структуры данных!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mubsrdL7CECm"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType, MapType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmTN8aYYCLaP"
   },
   "outputs": [],
   "source": [
    "arrayStructureSchema = StructType(\n",
    "    [\n",
    "        StructField(\n",
    "            \"name\",\n",
    "            StructType(\n",
    "                [\n",
    "                    StructField(\"firstname\", StringType(), True),\n",
    "                    StructField(\"middlename\", StringType(), True),\n",
    "                    StructField(\"lastname\", StringType(), True),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        StructField(\"hobbies\", ArrayType(StringType()), True),\n",
    "        StructField(\"properties\", MapType(IntegerType(), StringType()), True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yD1B3QxQCk2f"
   },
   "outputs": [],
   "source": [
    "structureData = [\n",
    "    ((\"James\", \"\", \"Smith\"), [\"car\", \"volleyball\"], {1: \"a\", 4: \"d\"}),\n",
    "    ((\"Michael\", \"Rose\", \"\"), [\"car\", \"football\"], {2: \"b\"}),\n",
    "    ((\"Robert\", \"\", \"Williams\"), [\"box\", \"music\"], {3: \"c\"}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ALozaKICfMB",
    "outputId": "049bfd25-ea50-4f8e-d30d-c175d2fcd31c"
   },
   "outputs": [],
   "source": [
    "df3 = spark.createDataFrame(data=structureData, schema=arrayStructureSchema)\n",
    "df3.printSchema()\n",
    "df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eLbNPk3YDiOY",
    "outputId": "47272a8d-4a8c-4d83-9959-e5463526522e"
   },
   "outputs": [],
   "source": [
    "df3.select(\"properties\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4uQ1cQpyCF_X"
   },
   "source": [
    "**Описание данных**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUn_TbKyCGCQ"
   },
   "source": [
    "Общее описание данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JFT3OfOsFTl4"
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\n",
    "    path=\"user_ratedmovies.dat\", sep=\"\\t\", header=True, inferSchema=True, schema=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4xsYm_0aCANH",
    "outputId": "ead70619-c78e-4462-d901-151d27cdefe0"
   },
   "outputs": [],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzoQTDS1CZdC",
    "outputId": "bc014253-b7b8-4bbb-ff13-1cbd0d1f8ea3"
   },
   "outputs": [],
   "source": [
    "df.summary().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTWN1cf_CrOT"
   },
   "source": [
    "Количество записей\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nVITW7_FCg7X",
    "outputId": "63bbd9ed-f17c-4f0b-b65b-91a7f0553368"
   },
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gei1DA_MDXEM"
   },
   "source": [
    "Количество партиций\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LxCM_uMCoOQ",
    "outputId": "33ca72db-be0c-4ba5-e4ef-154d7aa3f336"
   },
   "outputs": [],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uARz4b3lDdVF"
   },
   "source": [
    "Менять число партиций можно, все как с rdd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76UNLPKHDosI"
   },
   "outputs": [],
   "source": [
    "df = df.repartition(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JdVfa-ODDtXz",
    "outputId": "ea90d7dd-1609-4a11-8c8c-b3de1a11406a"
   },
   "outputs": [],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIDPMK-qDv7p"
   },
   "outputs": [],
   "source": [
    "df = df.coalesce(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hsG5g_aLDyPg",
    "outputId": "03ff6581-5c14-4720-aa4a-8474083f6fa9"
   },
   "outputs": [],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R30yappBElPl"
   },
   "source": [
    "**Различные методы**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTysHYCwEMQb"
   },
   "source": [
    "Ну теперь давайте тыкать\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-t0HREvEuXf"
   },
   "source": [
    "Удаляем дубликаты и помним, что есть actions и transformations, count заставит все сделать\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grCgDf3XEJAG"
   },
   "outputs": [],
   "source": [
    "df_without_duplicates = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFX2rl8lFFNg"
   },
   "source": [
    "Есть alias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0hXkMPVWFD0D"
   },
   "outputs": [],
   "source": [
    "df_without_duplicates = df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KdTTlyDXFVgV"
   },
   "source": [
    "Как удалить дубликаты по отдельным колонкам?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2WSm1GHBFK1Y"
   },
   "outputs": [],
   "source": [
    "df_without_duplicates = df.drop_duplicates([\"userID\", \"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2UDcQusBF0MU",
    "outputId": "e65e5072-907b-4dd5-f4ca-e665ac8407ec"
   },
   "outputs": [],
   "source": [
    "df_without_duplicates.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uu6IuhVlGAJ8",
    "outputId": "b8ee1a66-2a3e-43fe-98c0-bc9eed77dac4"
   },
   "outputs": [],
   "source": [
    "df_without_duplicates.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xLCdjnxQf-k"
   },
   "source": [
    "Корреляции\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_px4MeZ_QbWw",
    "outputId": "b847dcc6-8c94-4032-db4e-308fa3c2b9f9"
   },
   "outputs": [],
   "source": [
    "df.corr(\"rating\", \"date_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojnd-9aoQp-z",
    "outputId": "831e72ca-50f6-48b1-c721-89382fe76ccf"
   },
   "outputs": [],
   "source": [
    "df.corr(\"rating\", \"date_hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1yF8JE2QxCb",
    "outputId": "852f0c7a-b65e-4bee-ba50-c3ffe18ffc86"
   },
   "outputs": [],
   "source": [
    "df.corr(\"rating\", \"date_year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_EuaTuZHwbKI"
   },
   "source": [
    "Как закинуть данные в любимый pandas?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYMdZ4UIwius"
   },
   "source": [
    "Самый простой вариант - встроенный метод, но он жутко медленный при существенном объеме данных. Лучше сохранить паркет и считать через pd.read_parquet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U2K09OLKzoI1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "koXxQVt_wh82",
    "outputId": "0700c77d-2bea-422e-e1d5-ed13f42b8d3e"
   },
   "outputs": [],
   "source": [
    "%%timeit \n",
    "\n",
    "pandas_df = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "N4IMwKC1wsvH",
    "outputId": "99391bc4-c61a-4549-ad70-126235dc37ba"
   },
   "outputs": [],
   "source": [
    "pandas_df = df.toPandas()\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMyqh1n6yFln",
    "outputId": "465b6d3f-ea0b-4805-81fb-727c69cd7cb2"
   },
   "outputs": [],
   "source": [
    "pandas_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8g1GiYba-IY",
    "outputId": "70daf59b-a703-4534-eaba-a80a9d03cebb"
   },
   "outputs": [],
   "source": [
    "%%timeit \n",
    "\n",
    "pandas_df = pd.read_parquet('write_1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "e1VKNEWnbGAR",
    "outputId": "285d2102-9fc1-4360-9021-b29d94882ce9"
   },
   "outputs": [],
   "source": [
    "pandas_df = pd.read_parquet(\"write_1.parquet\")\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UafReEE9x-pV",
    "outputId": "ff07bc5c-c337-47f2-8faf-d4766193f21a"
   },
   "outputs": [],
   "source": [
    "pandas_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGsLsipKxqQx"
   },
   "source": [
    "Как говорили на лекции, может все упасть например тут (когда делаем toPandas). Как перейти к итератору?\n",
    "\n",
    "prefetchPartitions - подготавливать ли следующую партию данных, пока не запросили\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ys7zOtU2xx99"
   },
   "outputs": [],
   "source": [
    "iter_df = df.toLocalIterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBjM9GcryjUQ"
   },
   "outputs": [],
   "source": [
    "row = iter_df.send(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7IxLtM7YzLC3",
    "outputId": "51feadfa-18c4-49f1-95e8-150866e3a10f"
   },
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kdzog3jYv-nT",
    "outputId": "652cd527-dced-43e5-89ea-e9cb600adaeb"
   },
   "outputs": [],
   "source": [
    "row.asDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLMHUi8ozQl5"
   },
   "source": [
    "Отсюда идея: можно вытягивать данные по 1 записи и записывать в датафрейм. Долго, но зато отработает.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aNvszzqvzhON"
   },
   "outputs": [],
   "source": [
    "iter_df = df.toLocalIterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ogfT_1dv0FbK",
    "outputId": "2ff9b8ee-b16f-4708-9808-b735d0773f00"
   },
   "outputs": [],
   "source": [
    "list_of_rows = [value for value in iter_df]\n",
    "print(len(list_of_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tg3u4mWo0m2x",
    "outputId": "eaa6969d-6169-4637-a6ec-aeff45e0efc2"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehao9C3m0bSf"
   },
   "outputs": [],
   "source": [
    "pandas_df = pd.DataFrame(list_of_rows, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIEDYahwb9_E",
    "outputId": "421dc795-fcd8-4d81-cd2c-17e80c4fc1ce"
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "iter_df = df.toLocalIterator()\n",
    "list_of_rows = [value for value in iter_df]\n",
    "pandas_df = pd.DataFrame(list_of_rows, columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "KKr_PXmO0hK1",
    "outputId": "c33be59f-d426-4172-f09a-b17dbf5ced70"
   },
   "outputs": [],
   "source": [
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1jHiwbiZx7Ks",
    "outputId": "1b2d0400-b968-4029-bf29-4e6b65279981"
   },
   "outputs": [],
   "source": [
    "pandas_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tyNzrNDW3FI4"
   },
   "source": [
    "**Show**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYNJKbQJ2up1",
    "outputId": "384f3b08-fec3-42a3-910d-1b8fe6ecd306"
   },
   "outputs": [],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ymp1StL3aFi"
   },
   "source": [
    "Обрезаем до 2 символов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFXsxrXH3NQS",
    "outputId": "ebcd9fe0-229e-4038-e419-35eebafb3875"
   },
   "outputs": [],
   "source": [
    "df.show(10, truncate=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMoppJfS3klG"
   },
   "source": [
    "вертикальное отображение\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCuKzAS83dM4",
    "outputId": "37e71c07-6e47-49dc-85bc-80a8c2020fb2"
   },
   "outputs": [],
   "source": [
    "df.show(10, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVFKxBsuFU5i"
   },
   "source": [
    "**Select**\n",
    "\n",
    "В PySpark функция select() используется для выбора одного, нескольких столбцов по индексу, всех столбцов из списка и вложенных столбцов из фрейма данных. Функция PySpark select() является функцией преобразования, поэтому она возвращает новый фрейм данных с выбранными столбцами.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dliaTxGxFnzr",
    "outputId": "6f6223fe-187f-479e-f019-9458ddc3abdf"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cInhSbcBGtKn"
   },
   "source": [
    "Упс, pandas-style тут не приветствуется\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "Ms8Gqj0WGpOJ",
    "outputId": "99d37427-bb24-455c-b336-767cc2570c07"
   },
   "outputs": [],
   "source": [
    "df.userID.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rSF9GuB6Fwv7",
    "outputId": "8b88bd5e-7430-4760-eef8-6ee0d924fb87"
   },
   "outputs": [],
   "source": [
    "df.select(\"userID\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b8s0NRdtGHcZ"
   },
   "source": [
    "Куча вариантов, выбирайте любой\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8sUEL7yHF4mA",
    "outputId": "429ef80c-3843-47b7-96bd-642fa932daf1"
   },
   "outputs": [],
   "source": [
    "df.select(\"userID\", \"rating\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KynOoDxUF-DU",
    "outputId": "64b69d88-9610-493f-e0da-c1213a7934e7"
   },
   "outputs": [],
   "source": [
    "df.select([\"userID\", \"rating\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZrRyJPLGcHU",
    "outputId": "00be7187-cbbc-46b1-d5d2-01ddeed90999"
   },
   "outputs": [],
   "source": [
    "df.select(df.userID, df.rating).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YNkrq1TUGwSb",
    "outputId": "760db1b1-dcaa-43dd-952a-867f5e75aa1f"
   },
   "outputs": [],
   "source": [
    "df.select(df[\"userID\"], df[\"rating\"]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "La3Q3k01GZ3-",
    "outputId": "4b845fb9-f9f9-45cc-b5cc-af7058649f1e"
   },
   "outputs": [],
   "source": [
    "df.select(F.col(\"userID\"), F.col(\"rating\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Pfledp7JxFo"
   },
   "source": [
    "можно налету переименовать столбец\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "23c1EFh0JgCm",
    "outputId": "968550f1-20b5-4b5d-cbbd-9d64ad654b25"
   },
   "outputs": [],
   "source": [
    "df.select(df.userID, df.rating.alias(\"mark\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-15TG7h8G-7L",
    "outputId": "b4f25e3d-fdfd-4ce7-d803-838cc7e773c7"
   },
   "outputs": [],
   "source": [
    "# регулярки\n",
    "df.select(df.colRegex(\"`d+.*y`\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zRsPk3PItus"
   },
   "source": [
    "примеры с другим датафреймом, где структура сложнее\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0-EHUbgMJATb",
    "outputId": "ed9309b3-5a8e-4d47-c29f-22f5c82d7e86"
   },
   "outputs": [],
   "source": [
    "structureData = [\n",
    "    ((\"James\", \"\", \"Smith\"), \"36636\", \"M\", 3100),\n",
    "    ((\"Michael\", \"Rose\", \"\"), \"40288\", \"M\", 4300),\n",
    "    ((\"Robert\", \"\", \"Williams\"), \"42114\", \"M\", 1400),\n",
    "    ((\"Maria\", \"Anne\", \"Jones\"), \"39192\", \"F\", 5500),\n",
    "    ((\"Jen\", \"Mary\", \"Brown\"), \"\", \"F\", -1),\n",
    "]\n",
    "structureSchema = StructType(\n",
    "    [\n",
    "        StructField(\n",
    "            \"name\",\n",
    "            StructType(\n",
    "                [\n",
    "                    StructField(\"firstname\", StringType(), True),\n",
    "                    StructField(\"middlename\", StringType(), True),\n",
    "                    StructField(\"lastname\", StringType(), True),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        StructField(\"id\", StringType(), True),\n",
    "        StructField(\"gender\", StringType(), True),\n",
    "        StructField(\"salary\", IntegerType(), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "df2 = spark.createDataFrame(data=structureData, schema=structureSchema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOKRrq3OJBub",
    "outputId": "897ef423-f2e2-46fc-fdde-643401f094a0"
   },
   "outputs": [],
   "source": [
    "df2.select(\"name\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t7wWDSc0JGGH",
    "outputId": "f9a0064e-52c8-4cd1-e14c-9143796bcc61"
   },
   "outputs": [],
   "source": [
    "df2.select(\"name.lastname\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RCtpj47VJLhf",
    "outputId": "367ff968-cea4-4dff-ebf4-b678e99267c1"
   },
   "outputs": [],
   "source": [
    "df2.select(\"name.firstname\", \"name.lastname\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnz1-TbQVWhF"
   },
   "source": [
    "**withColumn**\n",
    "\n",
    "PySpark withColumn() - это функция преобразования (transform), которая используется для изменения значения, преобразования типа данных существующего столбца, создания нового столбца и многого другого. Поговорим о часто используемых операциях со столбцами данных PySpark, используя примеры.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gUhukrY0Y0Q2",
    "outputId": "6f29efb9-5c50-42fc-a550-f1fb46a2049e"
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4biHC1yYv7w"
   },
   "source": [
    "Меняем тип данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xGHnOBJ1YrGA",
    "outputId": "8ad5eb0f-5f62-4a0a-bd37-408ede93b098"
   },
   "outputs": [],
   "source": [
    "df.withColumn(\"date_month\", F.col(\"date_month\").cast(\"String\")).printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlM-ozjcZaJT"
   },
   "source": [
    "Модифицировать столбец/создать новый\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6afdpcQrZMWX",
    "outputId": "31d4a77e-3c05-4248-cb74-6993abdde05e"
   },
   "outputs": [],
   "source": [
    "df.withColumn(\"rating_x_10\", F.col(\"rating\") * 10).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSFyjtL6Z_WT"
   },
   "source": [
    "Делаем 2 константных столбца\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5tjCFJKAaLnO",
    "outputId": "a8aba11c-6c81-48e7-8373-bdef97ea10e0"
   },
   "outputs": [],
   "source": [
    "df.withColumn(\"fix_1\", F.lit(1)).withColumn(\"fix_2\", F.lit(2)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wq7AyqA7ajCw"
   },
   "source": [
    "**withColumnsRenamed**\n",
    "\n",
    "Предыдущий вариант не давал возможности переименовать столбцы, это можно сделать иначе\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhNQL1UaaoWn",
    "outputId": "2c66bfe6-661c-4494-aad0-de73ef9cc227"
   },
   "outputs": [],
   "source": [
    "df.withColumnRenamed(\"rating\", \"mark\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7XsfsdNbq_M"
   },
   "source": [
    "**filter (where) и иные филтрации**\n",
    "\n",
    "Функция PySpark filter() используется для фильтрации строк из RDD / DataFrame на основе заданного условия или выражения SQL, вы также можете использовать предложение where() вместо filter() обе эти функции работают аналогично.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVbRAIZ-eWm3"
   },
   "source": [
    "1 условие\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFzp724CddPb",
    "outputId": "e876e8eb-2457-4431-b558-7eb2845e269a"
   },
   "outputs": [],
   "source": [
    "df.filter(df.rating == 5.0).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vHYMQDRveND2",
    "outputId": "a4ea7878-553b-4d9d-a285-a7d7a427a713"
   },
   "outputs": [],
   "source": [
    "df.filter(~(df.rating == 5.0)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VF0jZSiFeRvT",
    "outputId": "85efce92-f71d-4286-b293-5358f06abcf3"
   },
   "outputs": [],
   "source": [
    "df.filter(\"rating = 5\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-tzppVSehGc"
   },
   "source": [
    "Несколько условий\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RG2nk91dekM_",
    "outputId": "271ee1a5-a8aa-434a-8eb0-ed875142a853"
   },
   "outputs": [],
   "source": [
    "df.filter((df.rating == 5.0) & (df.date_year == 2006)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OXGvcpqdfRK-",
    "outputId": "3e5e1dc3-e207-40cc-feaa-fdc27bdca575"
   },
   "outputs": [],
   "source": [
    "df.filter(\"(rating = 5.0) and (date_year = 2006)\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PPJrcN3Zh5zu",
    "outputId": "19dc8568-1989-4aa6-ac55-0846a669f977"
   },
   "outputs": [],
   "source": [
    "df.filter(\"(rating = 5.0) and (userID between 70 and 80)\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdE18CsVfepu"
   },
   "source": [
    "фильтр по списку значений из list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHYaVt1Sfix6"
   },
   "outputs": [],
   "source": [
    "years = [2006, 2007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CtScT6Ljf1f0",
    "outputId": "aa3673b9-2300-4679-afab-b2c0520471a9"
   },
   "outputs": [],
   "source": [
    "df.filter(df.date_year.isin(years)).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t8xkT6PxgJXy"
   },
   "source": [
    "проверим\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpQJJAchf-aY",
    "outputId": "66ee94db-3693-43a3-bbc3-a3a11bdd429b"
   },
   "outputs": [],
   "source": [
    "df.filter(df.date_year.isin(years)).select(\"date_year\").dropDuplicates().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baQHzWATiWPQ"
   },
   "source": [
    "создадим игрушечный датайфрейм для текстовых столбцов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j25PuaiOiVs0"
   },
   "outputs": [],
   "source": [
    "data2 = [\n",
    "    (2, \"Michael Rose\"),\n",
    "    (3, \"Robert Williams\"),\n",
    "    (4, \"Rames Rose\"),\n",
    "    (5, \"Rames Black\"),\n",
    "    (6, \"Albus Torch\"),\n",
    "    (7, \"Fred Tf\"),\n",
    "]\n",
    "\n",
    "\n",
    "df2 = spark.createDataFrame(data2, [\"id\", \"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h_3UfWtuisqY",
    "outputId": "39c24988-2089-4b1b-be23-9e83f6e8946c"
   },
   "outputs": [],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kfIw-U8pilfQ",
    "outputId": "f4b0679f-c971-4d7f-ae37-1a4707e2e550"
   },
   "outputs": [],
   "source": [
    "df2.filter('name like \"R%\"').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g_9M2YTCjpGf",
    "outputId": "3f899c73-3938-4f0a-e58b-3dc208f45501"
   },
   "outputs": [],
   "source": [
    "df2.filter(df2.name.startswith(\"R\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2qd6XuQbj1ca",
    "outputId": "6748f4be-b380-463d-c537-37ac06cd72b8"
   },
   "outputs": [],
   "source": [
    "df2.filter(df2.name.endswith(\"Tf\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPWVmWSFj5rA",
    "outputId": "600a4e23-98e9-4737-f9b4-15c065da55b7"
   },
   "outputs": [],
   "source": [
    "df2.filter(df2.name.contains(\"Wil\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfgGaL_zkIiF"
   },
   "source": [
    "Бывает, что у нас внутри датафрейма есть массив и с ним что-то хочется сделать\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LTpNzm_Lkl5d",
    "outputId": "ea2297d7-9114-4cc4-93bb-ebd82f0bf855"
   },
   "outputs": [],
   "source": [
    "arrayStructureSchema = StructType(\n",
    "    [\n",
    "        StructField(\n",
    "            \"name\",\n",
    "            StructType(\n",
    "                [\n",
    "                    StructField(\"firstname\", StringType(), True),\n",
    "                    StructField(\"middlename\", StringType(), True),\n",
    "                    StructField(\"lastname\", StringType(), True),\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        StructField(\"hobbies\", ArrayType(StringType()), True),\n",
    "        StructField(\"properties\", MapType(IntegerType(), StringType()), True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "structureData = [\n",
    "    ((\"James\", \"\", \"Smith\"), [\"car\", \"volleyball\"], {1: \"a\", 4: \"d\"}),\n",
    "    ((\"Michael\", \"Rose\", \"\"), [\"car\", \"football\"], {2: \"b\"}),\n",
    "    ((\"Robert\", \"\", \"Williams\"), [\"box\", \"music\"], {3: \"c\"}),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "df3 = spark.createDataFrame(data=structureData, schema=arrayStructureSchema)\n",
    "\n",
    "\n",
    "df3.printSchema()\n",
    "\n",
    "\n",
    "df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i_P75crVkoVP",
    "outputId": "2913bc46-c5a7-42d7-d2e2-572553d089fc"
   },
   "outputs": [],
   "source": [
    "df3.filter(F.array_contains(df3.hobbies, \"football\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7wIBH1plh4D"
   },
   "source": [
    "**Сортировка**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eid2Pim6oYdE"
   },
   "source": [
    "сделаем еще фильтрацию, чтобы увидеть результат (orderBy тут аналог)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3BY_-oj2mjs6",
    "outputId": "7e759324-ecd8-4963-8310-a3430ad90c1f"
   },
   "outputs": [],
   "source": [
    "df.filter(df.userID == 75).sort(df.date_minute, df.rating.desc()).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiqsFj72pkvM"
   },
   "source": [
    "**groupby**\n",
    "\n",
    "Когда мы выполняем groupBy() в PySpark DataFrame, он возвращает объект GroupedData, который содержит следующие агрегатные функции:\n",
    "\n",
    "min(), max(), mean(), count(), sum(), avg(), agg(), pivot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cL6AvkZPoeiy",
    "outputId": "1c583b07-847e-4c0f-aa68-4274cd33cd28"
   },
   "outputs": [],
   "source": [
    "df.groupby(\"date_year\").mean(\"rating\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QjgENxurJ_t"
   },
   "source": [
    "мы уже умеем применять разные методы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CvnbA2-aqzXI",
    "outputId": "4feba257-1e23-43e2-b444-1a3b8b9e9b29"
   },
   "outputs": [],
   "source": [
    "df.groupby(\"date_year\").mean(\"rating\").sort(\"date_year\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vBGHTsSxrUri",
    "outputId": "95996422-ac00-49e7-8400-97af54248d93"
   },
   "outputs": [],
   "source": [
    "df.filter(df.rating <= 2).groupby(\"date_year\").count().withColumnRenamed(\n",
    "    \"count\", \"number\"\n",
    ").sort(\"date_year\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_8epVoOrwG3"
   },
   "source": [
    "несколько колонок\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0SIzk9xOrsec",
    "outputId": "2d0035e4-c9c5-4e22-8989-14e24a352626"
   },
   "outputs": [],
   "source": [
    "df.groupBy(\"date_year\", \"date_month\").mean(\"rating\", \"userID\").sort(\n",
    "    \"date_year\", \"date_month\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qq4SNRAkukI2"
   },
   "source": [
    "Для того, чтобы делать несколько разных агрегаций и еще менять сразу имя столбца нужно немного изменить синтаксис\n",
    "\n",
    "И стоит помнить, что персентили тут считаются приближенно\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4OrMJN9ttWYQ",
    "outputId": "146b0eea-d7b7-4180-a5cc-6900f009141c"
   },
   "outputs": [],
   "source": [
    "df.groupBy(\"date_year\").agg(\n",
    "    F.min(\"rating\").alias(\"min_rating\"),\n",
    "    F.mean(\"rating\").alias(\"mean_rating\"),\n",
    "    F.max(\"rating\").alias(\"max_rating\"),\n",
    "    F.percentile_approx(\"rating\", 0.5).alias(\"median\"),\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahpMujLmcI1n"
   },
   "source": [
    "Еще можно сделать pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9J-VoOc0cWTd",
    "outputId": "8ce341f1-c739-44bd-c55b-433e27d7a1d6"
   },
   "outputs": [],
   "source": [
    "df.groupBy(\"date_year\").pivot(\"date_month\").mean(\"rating\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C0Xl9vFCu_eK"
   },
   "source": [
    "**Join's**\n",
    "\n",
    "Куда же без них. Что есть: INNER, LEFT OUTER, RIGHT OUTER, LEFT ANTI, LEFT SEMI, CROSS, SELF JOIN\n",
    "\n",
    "Благодаря оптимизации в датафреймах уже все хорошо работает, спасибо catalist, но чудеса не вечны и плохой код/незнание данных все равно даст о себе знать\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YneaY-MDxca7"
   },
   "source": [
    "Сделаем для себя несколько таблиц, чтобы можно было экспериментировать\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Jrab0pMxbJp"
   },
   "outputs": [],
   "source": [
    "df_mean_user_rating = (\n",
    "    df.groupBy(\"userID\")\n",
    "    .mean(\"rating\")\n",
    "\n",
    "    .withColumnRenamed(\"avg(rating)\", \"avg_rating_all\")\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "df_mean_user_rating_year = (\n",
    "    df.groupby(\"userID\", \"date_year\")\n",
    "    .mean(\"rating\")\n",
    "\n",
    "    .withColumnRenamed(\"avg(rating)\", \"avg_rating_year\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iOArojkkxHR0",
    "outputId": "7dfa5813-d6d8-4be3-bd72-da934f454434"
   },
   "outputs": [],
   "source": [
    "df_mean_user_rating.printSchema()\n",
    "\n",
    "df_mean_user_rating_year.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xejW3UuRzb0g"
   },
   "source": [
    "И давайте все в 1 блоке кода, чтобы не растягивать\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "sCpt6PH4zhGh",
    "outputId": "1c9f5c91-2ed6-41da-ba62-54737eaab8bf"
   },
   "outputs": [],
   "source": [
    "df.join(\n",
    "    df_mean_user_rating, on=df.userID == df_mean_user_rating.userID, how=\"inner\"\n",
    ").join(\n",
    "    df_mean_user_rating_year,\n",
    "    on=[\n",
    "        df.userID == df_mean_user_rating_year.userID,\n",
    "        df.date_year == df_mean_user_rating_year.date_year,\n",
    "    ],\n",
    "    how=\"inner\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12j__QNvZa5v"
   },
   "source": [
    "Надо удалить дублирующиеся столбцы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pNOXJ1Trwkmt"
   },
   "outputs": [],
   "source": [
    "res_join = (\n",
    "    df.alias(\"t\")\n",
    "    .join(\n",
    "        df_mean_user_rating.alias(\"t1\"),\n",
    "        on=F.col(\"t.userID\") == F.col(\"t1.userID\"),\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .drop(F.col(\"t1.userID\"))\n",
    "    .join(\n",
    "        df_mean_user_rating_year.alias(\"t2\"),\n",
    "        on=[\n",
    "            F.col(\"t.userID\") == F.col(\"t2.userID\"),\n",
    "            F.col(\"t.date_year\") == F.col(\"t2.date_year\"),\n",
    "        ],\n",
    "        how=\"inner\",\n",
    "    )\n",
    "    .drop(F.col(\"t2.userID\"))\n",
    "    .drop(F.col(\"t2.date_year\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-SFHiwk3bjar",
    "outputId": "ff362c97-1872-4755-e5c2-61aae6deef7d"
   },
   "outputs": [],
   "source": [
    "res_join.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5AnHARphOdO"
   },
   "source": [
    "**union и unionAll**\n",
    "\n",
    "Используются для объединения датафреймов с одинаковой структурой, используется union, так как unionAll с версии 2.0.0 более не используется\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUT2BY-Mh9mD"
   },
   "outputs": [],
   "source": [
    "df1 = df.filter(df.date_year == 2006)\n",
    "df2 = df.filter(df.date_year != 2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fAlbx9vNiJfl",
    "outputId": "7183d4d6-807c-469e-ea6a-d397eeb82584"
   },
   "outputs": [],
   "source": [
    "union_df = df1.union(df2)\n",
    "\n",
    "print(df.count(), union_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHSH3q7tixKe"
   },
   "source": [
    "Desclaimer: все по sql, надеюсь, помнят разницу между union и union all, когда union убирает дубликаты. Так вот pyspark ничего не удаляет, убрать дубликаты можно только через drop_duplicates, distinct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6i0lcIVAj7XS"
   },
   "source": [
    "Также при union pyspark делает объединение по столбцам as is, не пытаясь понять, что в одном датафрейме нужный стобец на 1 позиции, а в другом он на 5. Для этого с версии 3.1 есть замечательный метод unionByName\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwiOqXPolaNz"
   },
   "source": [
    "**UDF - user defined functions**\n",
    "\n",
    "из курса про rdd помним про map, тут тоже можно перегнать все в rdd и делать map, но можно и через udf. Стоит отметить, что при этом мы теряем возможность оптимизации и произодительность в dataframe, так как udf - black box для спарка.\n",
    "\n",
    "Но зато эти функции переиспользуемы и их можно применять в sql запросах, как те же udf в oracle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lk5nXLrEiqPa"
   },
   "outputs": [],
   "source": [
    "def udf_example(rating):\n",
    "    rating = rating * 20\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qkUtKFLM2BGT"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DK2Brnu2LSl"
   },
   "outputs": [],
   "source": [
    "my_udf = udf(lambda x: udf_example(x), DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B_I485a32XFD",
    "outputId": "6338bfbf-efe9-47c1-86c9-df8f606a7531"
   },
   "outputs": [],
   "source": [
    "df.select([\"userID\", \"movieID\", \"rating\"]).withColumn(\n",
    "    \"rating_100\", my_udf(F.col(\"rating\"))\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwrlR5GI3dxB"
   },
   "source": [
    "Для тех, кто любит декораторы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KaNfPZdg3dBs"
   },
   "outputs": [],
   "source": [
    "@udf(returnType=DoubleType())\n",
    "def udf_example_decorator(rating):\n",
    "    rating = rating * 20\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jnFY-jHV3qph",
    "outputId": "f24dba96-5736-42e7-d666-4be7cc5d68f2"
   },
   "outputs": [],
   "source": [
    "df.select([\"userID\", \"movieID\", \"rating\"]).withColumn(\n",
    "    \"rating_100\", udf_example_decorator(F.col(\"rating\"))\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLtZleE74gdv"
   },
   "source": [
    "Зарегистрируем функцию для будущих примеров с sql\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8QOkBZY4k-q",
    "outputId": "1a8f9fd0-42e9-4708-cc60-a6f53d7a5900"
   },
   "outputs": [],
   "source": [
    "spark.udf.register(\"udf_example_decorator\", udf_example_decorator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5P_NIuglWV72"
   },
   "source": [
    "**SQL**\n",
    "\n",
    "Ну раз уж пошла такая тема, давайте рассмотрим, как можно сделать все при помощи любимого SQL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3KC55x4XCET"
   },
   "source": [
    "можно делать TempView и GlodalTempView, отличие в том, что обычный view будет жить, пока жива сессия спрака, а глобальная, пока жив sparkcontext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zn1xgFFa5Fr1"
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7USYu6N142hn",
    "outputId": "05cd4aa6-9a51-4d86-e7f2-a4aad829cdf8"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "select userID, movieID, rating, udf_example_decorator(rating) as rating_100\n",
    "from\n",
    "df\n",
    "\"\"\"\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNdTc07RWlLd"
   },
   "source": [
    "Ну и наш join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXqOTAhHWkQ1"
   },
   "outputs": [],
   "source": [
    "df_mean_user_rating.createOrReplaceTempView(\"df_mean_user_rating\")\n",
    "df_mean_user_rating_year.createOrReplaceTempView(\"df_mean_user_rating_year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "slhrZnkeXgdo",
    "outputId": "cf132ced-86a8-4185-9b56-a3b17c83c204"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "select t.*, t1.avg_rating_all, t2.avg_rating_year\n",
    "from\n",
    "df t, df_mean_user_rating t1, df_mean_user_rating_year t2\n",
    "where\n",
    "    t.userID = t1.userID and\n",
    "    t.userID = t2.userID and\n",
    "    t.date_year = t2.date_year\n",
    "\"\"\"\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUh-iswqZLFy"
   },
   "source": [
    "**fill() и fillna()**\n",
    "\n",
    "Оба метода идентичны, заполняют пропуски\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CqDjntPTaMWK"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zu7pS9UVZKcY"
   },
   "outputs": [],
   "source": [
    "data2 = [\n",
    "    (2, \"Michael Rose\"),\n",
    "    (3, \"Robert Williams\"),\n",
    "    (4, \"Rames Rose\"),\n",
    "    (5, None),\n",
    "    (6, None),\n",
    "    (None, \"Fred Tf\"),\n",
    "]\n",
    "\n",
    "\n",
    "df2 = spark.createDataFrame(data2, [\"id\", \"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jtEyGTDFkPu"
   },
   "source": [
    "А где пропуски?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEQhiI-FFiLe",
    "outputId": "7dac39e0-b378-4f92-90ef-58f0cea66f54"
   },
   "outputs": [],
   "source": [
    "df2.select(\n",
    "    [F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in df2.columns]\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RwL5c9f1aZfQ",
    "outputId": "6d93d062-0f7c-41a4-d61d-ea6f7ce5f74a"
   },
   "outputs": [],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4ZY2Y9Lab8D",
    "outputId": "d6da863b-7a56-4c1a-e698-e8dbc73d0cde"
   },
   "outputs": [],
   "source": [
    "df2.fillna({\"id\": 0}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vyi4vYFSa_TS",
    "outputId": "a2f7fde4-77b0-45ac-d779-b81e16c257e3"
   },
   "outputs": [],
   "source": [
    "df2.fillna({\"id\": 0, \"name\": \"Unknown\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFF3UQJlbJsY"
   },
   "source": [
    "Аналогично\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DjH5G5DCbMJG",
    "outputId": "ef3532d3-b8e0-4a94-eaca-0fd1d83e536e"
   },
   "outputs": [],
   "source": [
    "df2.na.fill({\"id\": 0, \"name\": \"Unknown\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KS1BDHPNmKGX"
   },
   "source": [
    "Немного поговорим о том, как делаеть подвыборки\n",
    "\n",
    "**sample и sampleBy**\n",
    "\n",
    "Не забываем про возможную некоторую недетерминированность\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zuFgRqpDgmj6"
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3sUPPgLmJiW"
   },
   "outputs": [],
   "source": [
    "trans_data = spark.read.parquet(\n",
    "    \"/content/drive/MyDrive/Colab Notebooks/spark_transactions.parquet\"\n",
    ")\n",
    "\n",
    "\n",
    "trans_data = trans_data.withColumn(\n",
    "    \"target\", F.when(F.col(\"IsFraud\") == \"No\", 0).otherwise(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LV9Dc3_GmcoD",
    "outputId": "855dd48b-5700-4d98-f711-7d42b27c6b79"
   },
   "outputs": [],
   "source": [
    "trans_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yc7cxK3yno28",
    "outputId": "1697bd7a-b247-4d53-dc96-75f79fb1620a"
   },
   "outputs": [],
   "source": [
    "trans_data.select(F.mean(F.col(\"target\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JYcyQctEy1mY",
    "outputId": "eda9746e-0d2f-4bd8-8bec-63668ab177c0"
   },
   "outputs": [],
   "source": [
    "trans_data.select(\"target\").groupBy(\"target\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5uX2m5MEmeIm",
    "outputId": "42fce875-50f1-484a-b47a-fab66b9ad7ae"
   },
   "outputs": [],
   "source": [
    "trans_data_simple = trans_data.sample(withReplacement=False, fraction=0.1, seed=3)\n",
    "print(trans_data_simple.count())\n",
    "trans_data_simple.select(F.mean(F.col(\"target\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uotzZFIqnTEi"
   },
   "source": [
    "Стратификация\n",
    "\n",
    "Тут важно понимать, что это не scikit-learn и стратификация предполагает, что вы по какому-то полю можете выбрать определенную долю наблюдений по его значениям\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2MciDJrYnM-j",
    "outputId": "6be40735-1d85-4583-ba51-a56b14815341"
   },
   "outputs": [],
   "source": [
    "trans_data.sampleBy(F.col(\"target\"), fractions={1: 1.0}, seed=0).select(\n",
    "    \"target\"\n",
    ").groupBy(\"target\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "crv0BlfIzlYU"
   },
   "source": [
    "Не указали какой-то ключ - его доля будет 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NQBDyAfezrS4",
    "outputId": "7d4e68bb-60ee-4c13-da8f-019dc129807a"
   },
   "outputs": [],
   "source": [
    "trans_data.sampleBy(F.col(\"target\"), fractions={1: 1.0, 0: 0.1}, seed=0).select(\n",
    "    \"target\"\n",
    ").groupBy(\"target\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XBlXlCI0O0K"
   },
   "source": [
    "Оконные функции **F.func().over(Window.partitionBy().orderBy())**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-p4PyshB2jtk"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ovFXtw2j4VvG",
    "outputId": "49a86eec-69c5-499b-c948-f102b394db9b"
   },
   "outputs": [],
   "source": [
    "trans_data_simple.select(\"User\", \"Card\", \"Year\", \"Month\", \"Day\").withColumn(\n",
    "    \"rn_1\",\n",
    "    F.row_number().over(\n",
    "        Window.partitionBy(\"User\", \"Card\").orderBy(F.col(\"Year\").asc())\n",
    "    ),\n",
    ").withColumn(\n",
    "    \"rn_2\",\n",
    "    F.row_number().over(\n",
    "        Window.partitionBy(\"User\", \"Card\").orderBy(\n",
    "            F.col(\"Year\").asc(), F.col(\"Month\").desc()\n",
    "        )\n",
    "    ),\n",
    ").withColumn(\n",
    "    \"mean\", F.mean(\"Day\").over(Window.partitionBy(\"User\", \"Card\", \"Month\"))\n",
    ").withColumn(\n",
    "    \"lag\",\n",
    "    F.lag(\"Day\").over(\n",
    "        Window.partitionBy(\"User\", \"Card\", \"Month\").orderBy(\n",
    "            F.col(\"Year\").asc(), F.col(\"Month\").desc(), F.col(\"Day\").desc()\n",
    "        )\n",
    "    ),\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5kvR2tz8GzD"
   },
   "source": [
    "Сборка последовательностей через **collect_list()**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0yWD7_HZhklz",
    "outputId": "c3d4ccd3-fad0-4f81-cab5-b09a1bc91c94"
   },
   "outputs": [],
   "source": [
    "trans_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rf9_lhZwg951"
   },
   "outputs": [],
   "source": [
    "trans_data_simple_seq = trans_data_simple.select(\n",
    "    \"User\", \"Card\", F.struct(\"Amount\", \"Day\").alias(\"sequence\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zUhoyMlPh3Tv",
    "outputId": "613cb6f5-cc0f-4c6c-da12-2c66301cdcc0"
   },
   "outputs": [],
   "source": [
    "trans_data_simple_seq.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IsS936Krh9RH"
   },
   "outputs": [],
   "source": [
    "trans_data_simple_seq = trans_data_simple_seq.groupBy(\"User\", \"Card\").agg(\n",
    "    F.collect_list(\"sequence\").alias(\"sequence\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-NZsqmxiSSG",
    "outputId": "d8050751-b986-45b3-904d-90bcc68480a3"
   },
   "outputs": [],
   "source": [
    "trans_data_simple_seq.show(truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rd8ITh5XikuI"
   },
   "source": [
    "А что с этим делать дальше? Можно перейти к RDD и построчно обрабатывать\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jq8hyqcsikLw"
   },
   "outputs": [],
   "source": [
    "row = trans_data_simple_seq.rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TrbCyyt1ivcg",
    "outputId": "ae4e7fe5-8ca6-4e6b-a9a2-4033278f9326"
   },
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O30kjweEix_C",
    "outputId": "155a30c3-b539-4de5-ad40-44e08408447d"
   },
   "outputs": [],
   "source": [
    "row[0][\"sequence\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAVfOjcTcdGQ"
   },
   "source": [
    "**Домашнее задание**\n",
    "\n",
    "Куда же без домашки, верно?\n",
    "\n",
    "Есть данные по транзакциям клиентов, ваша задача состоит в анализе этих данных и подготовки к структуре, которая похожа на ту структуру, которая сейчас часто нами используется при построении моделей на транзакциях + промежуточные задания.\n",
    "\n",
    "Не забудьте делать всякие show после каждого задания, чтобы было видно результат\n",
    "\n",
    "**Файл spark_transactions.parquet можете забрать в папке с записями лекций**\n",
    "\n",
    "**Важно**\n",
    "В домашнем задании старайтесь использовать максимально dataframe api, а не sql запросы.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "conf = (\n",
    "    SparkConf()\n",
    "    .set(\"spark.ui.port\", \"4050\")\n",
    "    .set(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "    .set(\"spark.dynamicAllocation.enabled\", \"true\")\n",
    "    .set(\"spark.shuffle.service.enabled\", \"true\")\n",
    ")  # трекер, чтобы возвращать ресурсы\n",
    "sc = SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-0T0sTY5Odw"
   },
   "outputs": [],
   "source": [
    "trans_data = spark.read.parquet(\n",
    "    \"/content/drive/MyDrive/pyspark_winter_2023/lesson_3/spark_transactions.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULuAEhmOmEC4",
    "outputId": "e2d3d87f-c97f-46df-fead-09ca9e414261"
   },
   "outputs": [],
   "source": [
    "trans_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wTg-84Tr7tq4",
    "outputId": "6c7a44df-fc4d-408e-9587-2a2f21f676b3"
   },
   "outputs": [],
   "source": [
    "trans_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wa1YHO4iJNlU"
   },
   "source": [
    "Посмотрим на схему данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97WEy56hXtsj"
   },
   "outputs": [],
   "source": [
    "trans_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfi4rGq8IP70"
   },
   "source": [
    "Сколько в среднем транзакций у пользователя\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6tW6OGiXtsj"
   },
   "outputs": [],
   "source": [
    "aggregated = trans_data.groupBy(\"User\").agg(F.count(\"*\").alias(\"count\"))\n",
    "aggregated.agg(F.mean(\"count\").alias(\"Avg transaction count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQ65xaaxGfyZ"
   },
   "source": [
    "Сколько карт у пользователей в среднем\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3eJP7vzNXtsj"
   },
   "outputs": [],
   "source": [
    "cards = trans_data.groupBy(\"User\").agg(F.countDistinct(\"Card\").alias(\"cards_count\"))\n",
    "cards.agg(F.mean(\"cards_count\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQ5tOK9AJMbJ"
   },
   "source": [
    "Немного обработаем данные: Amount в float, из Time вытянем час транзакции и удалим исходный Time, Zip к типу int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9DfG79tXtsj"
   },
   "outputs": [],
   "source": [
    "trans_data = trans_data.withColumn(\"Amount\", F.substring(F.col(\"Amount\"), 2, 100))\n",
    "trans_data = trans_data.withColumn(\"Amount\", F.col(\"Amount\").cast(\"Double\"))\n",
    "trans_data = trans_data.withColumn(\"Zip\", F.col(\"Zip\").cast(\"int\"))\n",
    "trans_data = trans_data.withColumn(\"Hour\", F.substring(F.col(\"Time\"), 1, 2))\n",
    "trans_data = trans_data.withColumn(\"Hour\", F.col(\"Hour\").cast(\"int\"))\n",
    "trans_data = trans_data.drop(\"Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Km4bInOzTf2d"
   },
   "source": [
    "Посчитайте количество транзакций по годам, учитывая только те транзакции, объем которых был больше 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YXb_dT5BXtsj"
   },
   "outputs": [],
   "source": [
    "trans_data.filter(trans_data.Amount > 100.0).groupBy(\"Year\").count().withColumnRenamed(\n",
    "    \"count\", \"Transactions\"\n",
    ").orderBy(\"Year\", ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPQ3E9SGDtWJ"
   },
   "source": [
    "Определите, есть ли пропуски в данных по каждому столбцу\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wewZ9ZRZXtsj"
   },
   "outputs": [],
   "source": [
    "trans_data.select(\n",
    "    [\n",
    "        F.count(F.when(F.isnan(column) | F.col(column).isNull(), column)).alias(column)\n",
    "        for column in trans_data.columns\n",
    "    ]\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rg3ZKFXYGF1I"
   },
   "source": [
    "Заполните пропуски исходя из типа данных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlld3xRkXtsk"
   },
   "outputs": [],
   "source": [
    "trans_data = trans_data.fillna({\"MerchantState\": \"Unknown\", \"Zip\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKumnBpJNR1H"
   },
   "source": [
    "При помощи оконных функций для каждого клиента рассчитайте средний размер транзакции, количество транзакций и последнюю по дате транзакцию.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EGM5WttNRVL"
   },
   "outputs": [],
   "source": [
    "window_agg = Window.partitionBy(\"User\")\n",
    "trans_data = (\n",
    "    trans_data.withColumn(\"mean_amount\", F.avg(\"Amount\").over(window_agg))\n",
    "    .withColumn(\"count_amount\", F.count(\"Amount\").over(window_agg))\n",
    "    .withColumn(\"last_payment\", F.max(\"datetime\").over(window_agg))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_data.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkiD1y5xGfet"
   },
   "source": [
    "Теперь самое время сгруппировать данные по каждому клиенту (можно использовать collect_list для сбора данных после агрегации)\n",
    "Когда будете делать агрегацию, то возьмите только часть выборки, например, через sample, для всей выборки либо не хватит памяти, либо очень долго считать\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = trans_data.sample(fraction=0.01, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data = sample_data.groupBy([\"User\", \"Card\"]).agg(\n",
    "    F.collect_list(\"Amount\").alias(\"Amount\"),\n",
    "    F.collect_list(\"Year\").alias(\"Years\"),\n",
    "    F.collect_list(\"Month\").alias(\"Months\"),\n",
    "    F.collect_list(\"Day\").alias(\"Days\"),\n",
    "    F.collect_list(\"Hour\").alias(\"Time\"),\n",
    "    F.collect_list(\"MCC\").alias(\"MCC\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data.sort([\"User\", \"Card\"]).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66WJoh15jf0P"
   },
   "source": [
    "Напишите python функцию, которая возьмет данные после агрегации последовательностей, отсортирует их внутри по дате и времени и преобразует к формату python dict:\n",
    "{'User': User,\n",
    "'Card': Card,\n",
    "'sequence':{\n",
    "'amount': [последовательность],\n",
    "'year': [последовательность],\n",
    "'month': [последовательность],\n",
    "'day': [последовательность],\n",
    "'time': [последовательность],\n",
    "'MCC': [последовательность]\n",
    "}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDC5b3iBk0Ti"
   },
   "source": [
    "Выведите как пример одну преобразованную запись, результаты сохраните на диск в через rdd pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"User\", LongType(), True),\n",
    "        StructField(\"Card\", LongType(), True),\n",
    "        StructField(\n",
    "            \"sequence\",\n",
    "            StructType(\n",
    "                [\n",
    "                    StructField(\n",
    "                        \"amount\", ArrayType(DoubleType(), containsNull=False), True\n",
    "                    ),\n",
    "                    StructField(\n",
    "                        \"year\", ArrayType(LongType(), containsNull=False), True\n",
    "                    ),\n",
    "                    StructField(\n",
    "                        \"month\", ArrayType(LongType(), containsNull=False), True\n",
    "                    ),\n",
    "                    StructField(\"day\", ArrayType(LongType(), containsNull=False), True),\n",
    "                    StructField(\n",
    "                        \"time\", ArrayType(IntegerType(), containsNull=False), True\n",
    "                    ),\n",
    "                    StructField(\"MCC\", ArrayType(LongType(), containsNull=False), True),\n",
    "                ]\n",
    "            ),\n",
    "            True,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "SeqRow = Row(\"amount\", \"year\", \"month\", \"day\", \"time\", \"MCC\")\n",
    "OuterRow = Row(\"User\", \"Card\", \"sequence\")\n",
    "\n",
    "\n",
    "def make_row(user, card, amount, years, months, days, time, mcc):\n",
    "    return OuterRow(user, card, SeqRow(amount, years, months, days, time, mcc))\n",
    "\n",
    "\n",
    "make_row_udf = udf(make_row, schema)\n",
    "\n",
    "result = agg_data.withColumn(\n",
    "    \"data\",\n",
    "    make_row_udf(\n",
    "        col(\"User\"),\n",
    "        col(\"Card\"),\n",
    "        col(\"Amount\"),\n",
    "        col(\"Years\"),\n",
    "        col(\"Months\"),\n",
    "        col(\"Days\"),\n",
    "        col(\"Time\"),\n",
    "        col(\"MCC\"),\n",
    "    ),\n",
    ").select(\"data.*\")\n",
    "result.printSchema()\n",
    "result.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
